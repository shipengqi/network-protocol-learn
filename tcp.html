<!DOCTYPE html>
<html lang="en">
  <head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    <title>Network protocol learning | TCP </title>
    <meta name="description" content>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    

    <!-- fonts -->
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
    <link href="//fonts.googleapis.com/css?family=Ubuntu:300,400,500,600,700" rel="stylesheet">

    <!-- stylesheets -->
    <link rel="stylesheet" href="/network-protocol-learn/style/doc.css">

    <!-- favicon -->
    <link rel="icon" href="/network-protocol-learn/images/favicon.ico">

    

  </head>
  <body>

   <script>window.__INITIAL_STATE__ = {"page":{"title":"TCP","path":"tcp.html"},"data":{"navigation":{"logo":{"text":"Network Protocol Learn","type":"link","path":"index.html"},"main":[{"text":"IP","type":"link","path":"ip.html"},{"text":"物理层和链路层","type":"link","path":"physical_link.html"},{"text":"ICMP","type":"link","path":"icmp.html"},{"text":"网关","type":"link","path":"gateway.html"},{"text":"UDP","type":"link","path":"udp.html"},{"text":"TCP","type":"link","path":"tcp.html"},{"text":"HTTP","type":"link","path":"http.html"},{"text":"HTTPS","type":"link","path":"https.html"},{"text":"流媒体协议","type":"link","path":"stream.html"},{"text":"P2P 协议","type":"link","path":"p2p.html"},{"text":"DNS","type":"link","path":"dns.html"},{"text":"CDN","type":"link","path":"cdn.html"},{"text":"数据中心","type":"link","path":"data_center.html"},{"text":"VPN","type":"link","path":"vpn.html"},{"text":"移动网络","type":"link","path":"nemo.html"},{"text":"云中网络","type":"link","path":"cloud.html"},{"text":"容器网络","type":"link","path":"container.html"},{"text":"RPC","type":"link","path":"rpc.html"},{"text":"网络工具","type":"label"},{"text":"网络工具","type":"link","path":"net_tools.html"},{"text":"WireShark","type":"link","path":"wireshark.html"},{"text":"THEME","type":"label"},{"text":"使用文档主题","type":"link","path":"theme/theme-usage.html"},{"text":"SUPPORT AND FEEDBACK","type":"label"},{"text":"Raise an Issue on Github","type":"link","path":"https://github.com/shipengqi/network-protocol-learn/issues/new"}]}},"config":{"timezone":"UTC","root":"/network-protocol-learn/","time_format":"HH:mm:ss","theme":"../node_modules/hexo-theme-doc","theme_config":{"swagger_ui":{"version":2,"permalinks":true,"api_explorer":true,"download":"Download specification","show_extensions":false,"deep_linking":true,"display_operation_id":false,"doc_expansion":"none"},"search":{"skip":false,"background":false,"route":"/lunr.json"},"favicon":"images/favicon.ico"}}}</script>

    <div id="react-navigation-root"><div class="doc-navigation" data-reactroot><nav class="doc-navbar"><a href="/network-protocol-learn/index.html" class="doc-navbar__logo"><img src="/network-protocol-learn/images/logo.png" class="doc-navbar__logo__img"><span class="doc-navbar__logo__text">Network Protocol Learn</span></a><i class="dc-icon dc-icon--close dc-icon--interactive doc-sidebar-close doc-navbar__sidebar-close doc-navbar__sidebar-close--desktop"></i><i class="dc-icon dc-icon--menu dc-icon--interactive doc-sidebar-toggle doc-navbar__sidebar-toggle"></i></nav><nav class="doc-sidebar"><div class="doc-sidebar__vertical-menu"><i class="dc-icon dc-icon--menu dc-icon--interactive doc-sidebar-toggle doc-sidebar-toggle--primary doc-sidebar__vertical-menu__item"></i><i class="dc-icon dc-icon--search dc-icon--interactive doc-sidebar__vertical-menu__item doc-sidebar__vertical-menu__item--primary"></i></div><div class="doc-sidebar-content"><div class="doc-sidebar__search-form"></div><ul class="doc-sidebar-list"></ul></div></nav></div></div>
    <div class="doc-content">
  <div class="dc-page">
    <div class="dc-card">
      <div id="react-search-results-root"></div>
      <div id="page-content" class="doc-formatting">
        <h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><p>TCP 认为网络环境是恶劣的，丢包、乱序、重传，拥塞都是常有的事情，一言不合就可能送达不了，因而要从算法层面来保证可靠性。 主要有下<br>面几个方面：</p>
<ul>
<li>对每个包提供校验和</li>
<li>包的序列号解决了接收数据的乱序、重复问题</li>
<li>重传机制</li>
<li>流量控制、拥塞控制</li>
</ul>
<h2 id="什么是流"><a href="#什么是流" class="headerlink" title="什么是流"></a>什么是流</h2><p>TCP 面向字节流的协议。<strong>流的含义是没有固定的报文边界</strong>。</p>
<p>假设调用 2 次 write 函数往 socket 里依次写 500 字节、800 字节。write 函数只是把字节拷贝到内核缓冲区，最终会以多少条报文发送<br>出去是不确定的：</p>
<ul>
<li>情况 1：分为两条报文依次发出去 500 字节 和 800 字节数据</li>
<li>情况 2：两部分数据合并为一个长度为 1300 字节的报文，一次发送</li>
<li>情况 3：第一部分的 500 字节与第二部分的 500 字节合并为一个长度为 1000 字节的报文，第二部分剩下的 300 字节单独作为一个报文发送</li>
<li>情况 4：第一部分的 400 字节单独发送，剩下100字节与第二部分的 800 字节合并为一个 900 字节的包一起发送。</li>
<li>情况 N：更多可能的拆分组合</li>
</ul>
<p>上面出现的情况<strong>取决于诸多因素：路径最大传输单元 MTU、发送窗口大小、拥塞窗口大小等</strong>。</p>
<h2 id="TCP-包头"><a href="#TCP-包头" class="headerlink" title="TCP 包头"></a>TCP 包头</h2><p><img src="images/tcp/tcp-pack.jpg" alt></p>
<h3 id="序号"><a href="#序号" class="headerlink" title="序号"></a>序号</h3><p>通过 TCP 传输的字节流的每个字节都分配了序列号，<strong>序列号（Sequence number，SEQ）指的是本报文段第一个字节的序列号</strong>。为了解决乱序，重<br>复的问题。</p>
<p>序列号加上报文的长度，就可以确定传输的是哪一段数据。</p>
<p><strong>在 SYN 报文中，序列号用于交换彼此的初始序列号，在其它报文中，序列号用于保证包的顺序</strong>。</p>
<h4 id="初始序列号"><a href="#初始序列号" class="headerlink" title="初始序列号"></a>初始序列号</h4><p>在<strong>建立连接之初，通信双方都会各自选择一个序列号，称之为初始序列号</strong>（Initial Sequence Number, ISN）。在建立连接时，通信双方<br>通过 SYN 报文交换彼此的 ISN。</p>
<p>初始序列号是通过源地址、目标地址、源端口、目标端口和随机因子通过 MD5 进行进行计算。再加入时间因子计算得出。</p>
<p><img src="images/tcp/isn.jpg" alt></p>
<h3 id="确认序号"><a href="#确认序号" class="headerlink" title="确认序号"></a>确认序号</h3><p>TCP 使用<strong>确认序号</strong>（Acknowledgment number, ACK）来告知对方下一个期望接收的序列号，小于此确认号的所有字节都已经收到。<br>发出去的包要确认，不然怎么知道有没有收到。没有收到就重发，直到送达。</p>
<ul>
<li>ACK 包本身不需要被确认，否则就会无穷无尽死循环了</li>
<li>确认号永远是表示小于此确认号的字节都已经收到</li>
</ul>
<h3 id="状态位"><a href="#状态位" class="headerlink" title="状态位"></a>状态位</h3><p>双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</p>
<ul>
<li>SYN（Synchronize）：发起一个连接，同步双方的初始序列号</li>
<li>ACK（Acknowledge）：确认数据包</li>
<li>RST（Reset）：表示复位，用来关闭异常连接</li>
<li>FIN（Finish）：结束连接，通知对方我发完了所有数据，准备断开连接，后面我不会再发数据包给你了。</li>
<li>PSH（Push）：告知对方这些数据包收到以后应该马上交给上层应用，不能缓存起来</li>
</ul>
<h3 id="窗口大小"><a href="#窗口大小" class="headerlink" title="窗口大小"></a>窗口大小</h3><p>TCP 要做流量控制，双方各自声明一个窗口，表示自己当前能够的处理能力，避免发的太快或者太慢。TCP 还会做拥塞控制。<br>用于表示窗口大小的 “Window Size” 只有 16 位，也就是窗口大小最大是 65535 字节（64KB）。</p>
<h2 id="最大传输单元"><a href="#最大传输单元" class="headerlink" title="最大传输单元"></a>最大传输单元</h2><p>数据链路层传输的帧大小是有限制的，不能把一个太大的包直接塞给链路层，这个限制被称为<br><strong>最大传输单元</strong>（Maximum Transmission Unit, MTU）。</p>
<p>以太网的帧最小的帧是 64 字节，除去 14 字节头部和 4 字节 CRC 字段，有效荷载最小为 46 字节。最大的帧是 1518 字节，有效荷载最大<br>为 1500，这个值就是以太网的 MTU。计算一下传输 100KB 的数据，至少需要 （100 * 1024 / 1500) = 69 个以太网帧。</p>
<p><img src="images/tcp/eth-pack.jpg" alt></p>
<p><strong>不同的数据链路层的 MTU 是不同的</strong>。通过 <code>netstat -i</code> 可以查看网卡的 mtu。</p>
<h3 id="路径-MTU"><a href="#路径-MTU" class="headerlink" title="路径 MTU"></a>路径 MTU</h3><p>一个包从发送端传输到接收端，中间要跨越很多个网络，每条链路的 MTU 都可能不一样，这个通信过程中最小的 MTU 称为<strong>路径 MTU</strong>（Path MTU）。<br>就好比开车有时候开的是双向 4 车道，有时候可能是乡间小路一样。</p>
<p>路径 MTU 就跟木桶效应是一个道理，木桶的盛水量由最短的那条短板决定，<strong>路径 MTU 也是由通信链条中最小的 MTU 决定</strong>。</p>
<h2 id="IP-分段"><a href="#IP-分段" class="headerlink" title="IP 分段"></a>IP 分段</h2><p>IPv4 数据报的最大大小为 65535 字节，这已经远远超过了以太网的 MTU，而且有些网络还会开启巨帧（Jumbo Frame）能达到 9000 字节。<br>当一个 IP 数据包大于 MTU 时，IP 会把数据报文进行切割为多个小的片段(小于 MTU），使得这些小的报文可以通过链路层进行传输。</p>
<p>IP 头部中有一个 13 位表示<strong>分片偏移量</strong>的字段，用来表示该分段在原始数据报文中的位置。</p>
<p>例如下面的包：<br><img src="images/tcp/ip-offset.jpg" alt></p>
<p><code>More fragments</code> 处于 <code>set</code> 状态，表示后面还有其它分片，<code>Fragment offset: 185</code> 这里并不是表示分片偏移量为 185，wireshark 这<br>里显示的时候除以了 8，真实的分片偏移量为 <code>185 * 8 = 1480</code>。</p>
<p>如果 <code>More fragments</code> 处于 <code>Not set</code> 状态，表示这是最后一个分片了。</p>
<h2 id="TCP-最大段大小"><a href="#TCP-最大段大小" class="headerlink" title="TCP 最大段大小"></a>TCP 最大段大小</h2><p>TCP 为了避免被发送方分片，会主动把数据分割成小段再交给网络层，最大的分段大小称之为 MSS（Max Segment Size）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MSS = MTU - IP header头大小 - TCP 头大小</span><br></pre></td></tr></table></figure></p>
<p>这样一个 MSS 的数据恰好能装进一个 MTU 而不用分片。</p>
<p>在以太网中 TCP 的 <code>MSS = 1500（MTU） - 20（IP 头大小） - 20（TCP 头大小）= 1460</code>。</p>
<p>TCP 有一个 socket 选项 <code>TCP_MAXSEG</code>，可以用来设置此次连接的 MSS，如果设置了这个选项，则 MSS 不能超过这个值。</p>
<h2 id="端口号"><a href="#端口号" class="headerlink" title="端口号"></a>端口号</h2><p>端口号可以分为 3 类：</p>
<ul>
<li>熟知端口号（well-known port），熟知端口号由专门的机构<br>由 <a href="https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml" target="_blank" rel="noopener">IANA</a> 分配和控制，<br>范围为 <code>0~1023</code>。比如 HTTP 使用 80端口，HTTPS 使<br>用 443 端口，ssh 使用 22 端口。</li>
<li>已登记的端口（registered port）,已登记的端口不受 IANA 控制，不过由 IANA 登记并提供它们的使用情况清单。它的范围为 <code>1024～49151</code>。<br>49151 是取的端口号最大值 65536 的 3/4 减 1。已登记的端口占用了大约 75% 端口号的范围。常见的有 MySQL：3306，Redis：6379。</li>
<li>临时端口号（ephemeral port），如果应用程序没有调用 bind() 函数将 socket 绑定到特定的端口上，那么 TCP 和 UDP 会为该 socket 分配<br>一个唯一的临时端口。IANA 将 <code>49152～65535</code> 范围的端口称为临时端口（ephemeral port）或<strong>动态端口</strong>（dynamic port），也称为<br>私有端口（private port）。</li>
</ul>
<h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p><img src="images/tcp/handshake.jpg" alt></p>
<ol>
<li>客户端发送的一个段是 SYN 报文，这个报文只有 SYN 标记被置位。SYN 报文不携带数据，但是它占用一个序号（因为 SYN 段需要对方的确认，需要<br>占用一个序列号），下次发送数据序列号要加一。客户端会随机选择一个数字作为初始序列号（ISN）</li>
<li>服务端收到客户端的 SYN 段以后，将 SYN 和 ACK 标记都置位。</li>
<li>客户端发送三次握手最后一个 ACK 段，这个 ACK 段用来确认收到了服务端发送的 SYN 段。因为这个 ACK 段不携带任何数据，且不需要再<br>被确认，这个 ACK 段不消耗任何序列号。</li>
</ol>
<p><strong>三次握手除了建立连接，还要沟通 TCP 包的序号</strong>。A 告诉 B 我发起的请求从哪个序号开始，B 告诉 A，B 发起的包的序号从哪个开始。</p>
<p>为什么序号不都从 1 开始？是为了<strong>防止冲突</strong>。</p>
<p>例如，A 连上 B，发送了 1，2，3 三个包，但是 3 丢失了或者绕路了，重新发送，但是后来 A 又掉线了，重新连上 B 后，又从 1 开始发，但是<br>只发了 1，2，但是上次绕路的那个 3 又回来了，发给了 B，B 自然认为，这就是下一个包，于是发生了错误。</p>
<p>因而，<strong>每个连接都要有不同的序号，起始序号是随时间变化的，32 位，每 4S 加一</strong>。</p>
<h3 id="为什么握手要三次"><a href="#为什么握手要三次" class="headerlink" title="为什么握手要三次"></a>为什么握手要三次</h3><p>为什么是三次，不是两次或者四次？因为通信双方都要保证通信可以有来有回。例如，A 和 B，A 发起一个连接（第一次握手），B 收到请求，<br>并发送应答给 A（第二次握手），说明 B 可以建立连接，但 B 不知道 A 是否收到应答包，可能丢失了，所以 A 需要应答 B 的应答包<br>（第三次握手），B 收到这个消息，才能确认连接建立。</p>
<p>这也就是说，其实四次握手甚至更多也是可以的，但是只要双方的消息有去有回，就基本可以了。</p>
<p>如果 A 在建立连接后，就是不发数据。我们在程序设计的时候，可以要求开启 keepalive 机制，即使没有真实的数据包，也有<strong>探活包</strong>。另外，<br>作为服务端 B 的程序设计者，对于 A 这种长时间不发包的客户端，可以主动关闭，从而空出资源来给其他客户端使用。</p>
<h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p><img src="images/tcp/wave.jpg" alt></p>
<p>A：B 啊，我不想玩了。<br>B：哦，你不想玩了啊，我知道了。</p>
<p>这个时候，还只是 A 不想玩了，也即 A 不会再发送数据，但是 B 能不能在 ACK 的时候，直接关闭呢？当然不可以了，很有可能 A 是发完了最后的<br>数据就准备不玩了，但是 B 还没做完自己的事情，还是可以发送数据的，所以称为<strong>半关闭</strong>（half-close）的状态。</p>
<p>B：A 啊，好吧，我也不玩了，拜拜。<br>A：好的，拜拜</p>
<p>这样整个连接就关闭了。</p>
<blockquote>
<p>FIN 段是可以携带数据的，比如客户端可以在它最后要发送的数据块可以“捎带” FIN 段。</p>
</blockquote>
<p>但是这个过程有没有异常情况呢？</p>
<ol>
<li>A 说完“不玩了”之后，直接跑路，是会有问题的，因为 B 还没有发起结束，而如果 A 跑路，B 就算发起结束，也得不到回答，B 就不知<br>道该怎么办了。</li>
<li>A 说完“不玩了”，B 直接跑路，也是有问题的，因为 A 不知道 B 是还有事情要处理，还是过一会儿会发送结束。A 没有收到回复，则 A 会重新<br>发送“不玩了”</li>
</ol>
<p>TCP 协议专门设计了几个状态来处理这些问题。</p>
<p>A 收到 “B 说知道了”，就进入 FIN_WAIT_2 的状态，如果这个时候 B 直接跑路，则 A 将永远在这个状态。TCP 协议里面并没有对这个状态的<br>处理，但是 Linux 有，可以调整 <code>tcp_fin_timeout</code> 这个参数，设置一个<strong>超时时间</strong>。</p>
<p>如果 B 没有跑路，发送了 “B 也不玩了” 的请求到达 A 时，A 发送“知道 B 也不玩了”的 ACK 后，从 FIN_WAIT_2 状态结束，按说 A 可以跑路了，<br>但是最后的这个 ACK 万一 B 收不到呢？则 B 会重新发一个“B 不玩了”，这个时候 A 已经跑路了的话，B 就再也收不到 ACK 了，因而 TCP 协议要<br>求 A 最后等待一段时间 TIME_WAIT，这个时间要足够长，长到如果 B 没收到 ACK 的话，“B 说不玩了”会重发的，A 会重新发一个 ACK 并且足够时<br>间到达 B。</p>
<p>A 直接跑路还有一个问题是，A 的端口就直接空出来了，但是 B 不知道，B 原来发过的很多包很可能还在路上，如果 A 的端口被一个新的应用占用了，<br>这个新的应用会收到上个连接中 B 发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等<br>到原来 B 发送的所有的包都死翘翘，再空出端口来。</p>
<p>等待的时间设为 2MSL，<strong>MSL 是 Maximum Segment Lifetime，报文最大生存时间</strong>，它是任何报文在网络上存在的最长时间，超过这个时间报<br>文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此<br>值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟<br>和 2 分钟等。</p>
<p>还有一个异常情况就是，B 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，怎么办呢？按照 TCP 的原理，B 当然还会重发 FIN，这个时<br>候 A 再收到这个包之后，A 就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，于是就直接发送 RST，B 就知道 A 早<br>就跑了。</p>
<h3 id="为什么时间是两个-MSL"><a href="#为什么时间是两个-MSL" class="headerlink" title="为什么时间是两个 MSL"></a>为什么时间是两个 MSL</h3><ul>
<li>1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端</li>
<li>1 个 MSL 确保对端没有收到 ACK 时，重传的 FIN 报文可以到达，避免因为无法重传 ACK，被动关闭方因此不能及时可靠释放。</li>
</ul>
<h3 id="挥手可以变为三次吗"><a href="#挥手可以变为三次吗" class="headerlink" title="挥手可以变为三次吗"></a>挥手可以变为三次吗</h3><p><img src="images/tcp/wave-four-three.jpg" alt></p>
<p>是可以的，因为有<strong>延迟确认</strong>的存在，第二步的 ACK 经常会跟随第三步的 FIN 包一起捎带回客户端。</p>
<h2 id="TCP-状态机"><a href="#TCP-状态机" class="headerlink" title="TCP 状态机"></a>TCP 状态机</h2><p><img src="images/tcp/tcp-status.jpg" alt></p>
<h3 id="CLOSED"><a href="#CLOSED" class="headerlink" title="CLOSED"></a>CLOSED</h3><p>这个状态是一个<strong>假想</strong>的状态，是 TCP 连接还未开始建立连接或者连接已经彻底释放的状态。</p>
<p>从 CLOSE 状态转换为其它状态有两种可能：</p>
<ul>
<li>主动打开（Active Open），客户端主动发送一个 SYN 包准备三次握手，被称为<strong>主动打开（Active Open）</strong></li>
<li>被动打开（Passive Open），服务端会监听一个特定的端口，等待客户端的新连接，同时会进入 LISTEN 状态，称为<strong>被动打开</strong></li>
</ul>
<h3 id="LISTEN"><a href="#LISTEN" class="headerlink" title="LISTEN"></a>LISTEN</h3><p>通常是服务端调用 bind、listen 系统调用监听特定端口时进入到LISTEN状态，等待客户端发送 SYN 报文三次握手建立连接。</p>
<h3 id="SYN-SENT"><a href="#SYN-SENT" class="headerlink" title="SYN-SENT"></a>SYN-SENT</h3><p>客户端发送 SYN 报文等待 ACK 的过程进入 SYN-SENT状态。同时会开启一个定时器，如果超时还没有收到 ACK 会重发 SYN。</p>
<h3 id="SYN-RCVD"><a href="#SYN-RCVD" class="headerlink" title="SYN-RCVD"></a>SYN-RCVD</h3><p>服务端收到 SYN 报文以后会回复 SYN+ACK，然后进入 SYN-RCVD 状态，等待对端 ACK。</p>
<h3 id="ESTABLISHED"><a href="#ESTABLISHED" class="headerlink" title="ESTABLISHED"></a>ESTABLISHED</h3><p>SYN-SENT 或者 SYN-RCVD 状态的连接收到对端确认 ACK 以后进入 ESTABLISHED 状态，连接建立成功。</p>
<h3 id="FIN-WAIT-1"><a href="#FIN-WAIT-1" class="headerlink" title="FIN-WAIT-1"></a>FIN-WAIT-1</h3><p>主动关闭的一方发送了 FIN 包，等待对端回复 ACK 时进入 FIN-WAIT-1 状态。</p>
<h3 id="FIN-WAIT-2"><a href="#FIN-WAIT-2" class="headerlink" title="FIN-WAIT-2"></a>FIN-WAIT-2</h3><p>处于 FIN-WAIT-1 状态的连接收到 ACK 确认包以后进入 FIN-WAIT-2 状态，这个时候主动关闭方的 FIN 包已经被对方确认，等待被<br>动关闭方发送 FIN 包。</p>
<h3 id="CLOSE-WAIT"><a href="#CLOSE-WAIT" class="headerlink" title="CLOSE-WAIT"></a>CLOSE-WAIT</h3><p>当有一方想关闭连接的时候，发送 FIN 包给对端，这个被动关闭方，收到 FIN 包以后进入 CLOSE-WAIT 状态。</p>
<h3 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME-WAIT"></a>TIME-WAIT</h3><p>TIME-WAIT 是收到了被动关闭方的 FIN 包，发送确认 ACK 给对端，开启 2MSL 定时器，定时器到期时进入 CLOSED 状态，连接释放。</p>
<h3 id="LAST-ACK"><a href="#LAST-ACK" class="headerlink" title="LAST-ACK"></a>LAST-ACK</h3><p>LAST-ACK 顾名思义等待最后的 ACK。是被动关闭的一方，发送 FIN 包给对端等待 ACK 确认时的状态。<br>当收到 ACK 以后，进入 CLOSED 状态，连接释放。</p>
<h3 id="CLOSING"><a href="#CLOSING" class="headerlink" title="CLOSING"></a>CLOSING</h3><p>CLOSING状态在<strong>同时关闭</strong>情况下出现。这里的同时其实并不是时间意义上的同时，而是指的是在发送 FIN 包还未收到确认之前，<br>收到了对端的 FIN 的情况。</p>
<p><img src="images/tcp/both-off.jpg" alt></p>
<ol>
<li>最初客户端和服务端都处于 ESTABLISHED 状态</li>
<li>客户端发送 FIN 包，等待对端对这个 FIN 包的 ACK，随后进入 FIN-WAIT-1 状态</li>
<li>处于 FIN-WAIT-1 状态的客户端还没有等到 ACK，收到了服务端发过来的 FIN 包</li>
<li>收到 FIN 包以后客户端会发送对这个 FIN 包的的确认 ACK 包，同时自己进入 CLOSING 状态，继续等自己 FIN 包的 ACK</li>
<li>处于 CLOSING 状态的客户端终于等到了 ACK，随后进入 TIME-WAIT</li>
<li>在 TIME-WAIT 状态持续 2*MSL，进入 CLOSED 状态</li>
</ol>
<h2 id="TFO"><a href="#TFO" class="headerlink" title="TFO"></a>TFO</h2><h2 id="重传机制"><a href="#重传机制" class="headerlink" title="重传机制"></a>重传机制</h2><h3 id="ACK-是表示这之前的包都已经全部收到"><a href="#ACK-是表示这之前的包都已经全部收到" class="headerlink" title="ACK 是表示这之前的包都已经全部收到"></a>ACK 是表示这之前的包都已经全部收到</h3><p>如果发送 5000 个字节的数据包，因为 MSS 的限制每次传输 1000 个字节，分 5 段传输：</p>
<p><img src="images/tcp/ack-retransmission.jpg" alt></p>
<p>数据包 1 发送的数据正常到达接收端，接收端回复 ACK 1001，表示 seq 为 1001 之前的数据包都已经收到，下次从 1001 开始发。<br>数据包 2（1001:2001）因为某些原因未能到达服务端，其他包正常到达，这时接收端也不能 ack 3 4 5 数据包，因为数据包 2 还没收到，接收端只能<br>回复 ack 1001。第 2 个数据包重传成功以后服务器会回复 5001，表示 seq 为 5001 之前的数据包都已经收到了。</p>
<h3 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h3><p><strong>超时重试</strong>，也即对每一个发送了，但是没有 ACK 的包，都有设一个定时器，超过了一定的时间，就重新尝试。但是这个超时的时间如何评估呢？这<br>个时间不宜过短，时间必须大于<strong>往返时间 RTT</strong>，否则会引起不必要的重传。也不宜过长，这样超时时间变长，访问就变慢了。</p>
<p>估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除<br>了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为<strong>自适应重传<br>算法（Adaptive RetransmissionAlgorithm）</strong>。</p>
<p>如果数据包 2 丢了，重传之后又丢了，<strong>TCP 的策略是超时间隔加倍。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。<br>两次超时，就说明网络环境差，不宜频繁反复发送</strong>。</p>
<h3 id="快速重传与-SACK"><a href="#快速重传与-SACK" class="headerlink" title="快速重传与 SACK"></a>快速重传与 SACK</h3><p>超时触发重传存在的问题是，超时周期可能相对较长。有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检<br>测到了数据流中的一个间格，于是发送三个冗余的 ACK，客户端收到 3 个或以上重复 ACK，就在定时器过期之前，重传丢失的报文段。</p>
<p>例如，接收方发现数据包 3、4、5 都已经接收了，就是 2 没来，那肯定是丢了，于是发送三个 1001 的 ACK，要求下一个是 2。客户端<br>收到 3 个 1001 ACK，就会发现 2 的确丢了，不等超时，马上重发。</p>
<h4 id="SACK"><a href="#SACK" class="headerlink" title="SACK"></a>SACK</h4><p>有一个问题，发送 3、4、5 包收到的全部是 ACK=1001，快速重传解决了一个问题: 需要重传。因为除了 2 号包，3、4、5 包也有可能丢失，那到底<br>是只重传数据包 2 还是重传 2、3、4、5 所有包？</p>
<p>解决办法就是在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方，例如：</p>
<ul>
<li>收到 3 号包的时候在 ACK 包中告诉发送端：我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:3001] 区间的包我也收到了</li>
<li>收到 4 号包的时候在 ACK 包中告诉发送端：我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:4001] 区间的包我也收到了</li>
<li>收到 5 号包的时候在 ACK 包中告诉发送端：我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:5001] 区间的包我也收到了</li>
</ul>
<p>这样发送端就清楚知道只用重传 2 号数据包就可以了，数据包 3、4、5已经确认无误被对端收到。这种方式被称<br>为 <strong>SACK（Selective Acknowledgment）</strong>。</p>
<p><img src="images/tcp/sack.jpg" alt></p>
<h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>TCP 会把要发送的数据放入发送缓冲区（Send Buffer)，接收到的数据放入接收缓冲区（Receive Buffer），应用程序会不停的读取接收缓冲<br>区的内容进行处理。</p>
<p>流量控制做的事情就是，如果接收缓冲区已满，发送端应该停止发送数据。那发送端怎么知道接收端缓冲区是否已满呢？</p>
<p>为了控制发送端的速率，TCP 在收到数据包回复的 ACK 包里会带上自己接收窗口的大小，接收端需要根据这个值调整自己的发送策略。</p>
<h3 id="发送窗口和接收窗口"><a href="#发送窗口和接收窗口" class="headerlink" title="发送窗口和接收窗口"></a>发送窗口和接收窗口</h3><p><img src="images/tcp/wireshark-win.jpg" alt></p>
<p>wireshark 抓包中显示的 win=29312 指的就是<strong>接收窗口</strong>的大小。对方收到以后，会把自己的<strong>发送窗口</strong>限制在 29312 大小<br>之内。如果接收端处理能力有限，导致自己的接收缓冲区满，接收窗口大小为 0，发送端应该停止发送数据。</p>
<h4 id="发送窗口"><a href="#发送窗口" class="headerlink" title="发送窗口"></a>发送窗口</h4><p><img src="images/tcp/aw.jpg" alt></p>
<p>发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分：</p>
<ul>
<li>红色部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。</li>
<li>蓝色部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。</li>
<li>绿色部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。</li>
<li>黄色部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。</li>
</ul>
<p>发送窗口的大小就是蓝色部分加上绿色部分。</p>
<p>可用窗口是发送端还能发送的最大数据包大小，就是绿色部分。</p>
<p>窗口的<strong>左边界</strong>表示成功发送并已经被接收方确认的最大字节序号，窗口的<strong>右边界</strong>是发送方当前可以发送的最大字节序号，滑动窗口的大小等于<br>右边界减去左边界。</p>
<p>当上图中的可用区域的 6 个字节（46~51）发送出去，可用窗口区域减小到 0，这个时候除非收到接收端的 ACK 数据，否则发送端将不能发送数据。<br>如果使用 wireshark 抓包，可以看到 TCP Window Full，表示<strong>包的发送方已经把对方所声明的接收窗口耗尽了</strong>。<br><img src="images/tcp/aw2.jpg" alt></p>
<h4 id="TCP-Zero-Window"><a href="#TCP-Zero-Window" class="headerlink" title="TCP Zero Window"></a>TCP Zero Window</h4><p>TCP zero window 是站在<strong>接收端</strong>角度来说的，TCP 包中 <code>win=</code> 表示接收窗口的大小，表示接收端还有多少缓冲区可以接收数据，当窗<br>口变成 0 时，表示接收端不能暂时不能再接收数据了。 </p>
<p><img src="images/tcp/recvbuffer.jpg" alt></p>
<p>一开始三次握手确定接收窗口大小为 360 字节。</p>
<ol>
<li>发送端发送 140 字节给接收端，此时因为 140 字节在途未确认，所以它的可用滑动窗口大小为：360 - 140 = 220</li>
<li>接收端收到 140 字节以后，将这 140 字节放入TCP 接收区缓冲队列。正常情况下，接收端处理的速度非常快，这 140 字节会马上被应<br>用层取走并释放这部分缓冲区，同时发送确认包给发送端，这样接收端的窗口大小（RCV.WND)马上可以恢复到 360 字节，发送端收到确认包以<br>后也马上将可用发送滑动窗口恢复到 360 字节。但是如果因为高负载等原因，导致 TCP 没有立马处理接收到的数据包，收到的 140 字节没能全<br>部被取走，这个时候 TCP 会在返回的 ACK 里携带它建议的接收窗口大小，因为自己的处理能力有限，那就告诉对方下次发少一点数据。假设如上<br>图的场景，收到了 140 字节数据，现在只能从缓冲区队列取走 40 字节，还剩下 100 字节留在缓冲队列中，接收端将接收窗口从<br>原来的 360 减小 100 变为 260。</li>
<li>发送端接收到 ACK 以后，根据接收端的指示，将自己的发送滑动窗口减小到 260。所有的数据都已经被确认，这时候可用窗口大小<br>也等于 260</li>
<li>发送端继续发送 180 字节的数据给接收端，可用窗口= 260 - 180 = 80。</li>
<li>接收端收到 180 字节的数据，因为负载高等原因，没有能取走数据，将接收窗口再降低 180，变为 80，在回复给对端的 ACK 里携带回去。</li>
<li>发送端收到 ACK 以后，将自己的发送窗口减小到 80，同时可用窗口也变为 80</li>
<li>发送端继续发送 80 字节数据给接收端，在未确认之前在途字节数为 80，发送端可用窗口变为 0</li>
<li>接收端收到 80 字节的数据，放入接收区缓冲队列，但是入之前原因，没能取走，滑动窗口进一步减小到 0，在回复的 ACK 里捎带回去</li>
<li>发送端收到 ACK，根据发送端的指示，将自己的滑动窗口总大小减小为 0</li>
</ol>
<h5 id="零窗口探测包"><a href="#零窗口探测包" class="headerlink" title="零窗口探测包"></a>零窗口探测包</h5><p>现在发送端的滑动窗口变为 0 了，如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时<br>候，<strong>要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大<br>小，或者缓冲区一半为空，才更新窗口</strong>。</p>
<h2 id="拥塞控制问题"><a href="#拥塞控制问题" class="headerlink" title="拥塞控制问题"></a>拥塞控制问题</h2><p>拥塞控制的问题，也是通过窗口的大小来控制的，前面的<strong>滑动窗口 rwnd 是怕发送方把接收方缓存塞满，而拥塞窗口 cwnd，是怕把网络塞满</strong>。</p>
<p>拥塞窗口初始值等于操作系统的一个变量 <code>initcwnd</code>，最新的 linux 系统 <code>initcwnd</code> 默认值等于 10。</p>
<p><strong>真正的发送窗口大小</strong> = <strong>接收端接收窗口大小</strong> 与 <strong>发送端自己拥塞窗口大小两者的最小值</strong>。</p>
<p>如果接收窗口比拥塞窗口小，表示接收端处理能力不够。如果拥塞窗口小于接收窗口，表示接收端处理能力 ok，但网络拥塞。</p>
<p>发送端和接收端不会交换 cwnd 这个值，这个值是维护在发送端本地内存中的一个值。</p>
<p><strong>TCP 的拥塞控制就是在不堵塞，不丢包的情况下，尽量发挥带宽</strong>。</p>
<h3 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h3><p>TCP 的拥塞控制主要来避免两种现象，包丢失和超时重传。一旦出现了这些现象就说明，发送速度太快了，要慢一点。但是一开始我怎么知道速度多快<br>呢，我怎么知道应该把窗口调整到多大呢？</p>
<p>每个 TCP 连接都有一个拥塞窗口的限制，最初这个值很小，随着时间的推移，每次发送的数据量如果在不丢包的情况下，“慢慢”的递增，这种机<br>制被称为<strong>慢启动</strong>。</p>
<p>拥塞控制是从整个网络的大局观来思考的，如果没有拥塞控制，某一时刻网络的时延增加、丢包频繁，发送端疯狂重传，会造成网络更重的负担，而更<br>重的负担会造成更多的时延和丢包，形成雪崩的网络风暴。</p>
<p>这个算法的过程如下：</p>
<ol>
<li>三次握手以后，双方通过 ACK 告诉了对方自己的接收窗口（rwnd）的大小，之后就可以互相发数据了</li>
<li>通信双方各自初始化自己的「拥塞窗口」（Congestion Window，cwnd）大小。</li>
<li>cwnd 初始值较小时，每收到一个 ACK，cwnd + 1，每经过一个 RTT，cwnd 变为之前的两倍。 </li>
</ol>
<p>假设 RTT 为 50ms，客户端和服务端的接收窗口为 65535 字节（64KB），初始拥塞窗口为：10 段（MSS），那么要达到 64KB 的吞吐量，<br>拥塞窗口的段数 = 65535 / 1460 = 45 段，需要的 RTT 次数 = log2（45 / 10）= 2.12 次，需要的时间 = 50 * 2.12 = 106ms。<br>也就是客户端和服务器之间的 64KB 的吞吐量，需要 2.12 次 RTT，100ms 左右的延迟。</p>
<h3 id="慢启动阈值"><a href="#慢启动阈值" class="headerlink" title="慢启动阈值"></a>慢启动阈值</h3><p>慢启动拥塞窗口（cwnd）肯定不能无止境的指数级增长下去，否则拥塞控制就变成了拥塞失控了，它的阈值<br>称为<strong>慢启动阈值</strong>（Slow Start Threshold，ssthresh）</p>
<ul>
<li>当 cwnd &lt; ssthresh 时，拥塞窗口按指数级增长（慢启动）</li>
<li>当 cwnd &gt; ssthresh 时，拥塞窗口按线性增长（拥塞避免）</li>
</ul>
<h3 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h3><p>当 cwnd &gt; ssthresh 时，拥塞窗口进入<strong>拥塞避免</strong>（Congestion Avoidance）阶段。</p>
<p>每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加 1/8，八个确认一共 cwnd 增<br>加 1，于是一次能够发送九个，变成了线性增长。但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子<br>降低倒水的速度，等待溢出的水慢慢渗下去。拥塞的一种表现形式是丢包，需要超时重传，这个时候，将 sshresh 设为 cwnd/2，将 cwnd 设为 1，重<br>新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。</p>
<p>当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部<br>分没丢，只丢了一小部分，cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh +3，也就是没有一夜回到<br>解放前，而是还在比较高的值，呈线性增长。就像前面说的一样，正是这种知进退，使得时延很重要的情况下，反而降低了速度。但是如果你仔细想一下，<br>TCP 的拥塞控制主要来避免的两个现象都是有问题的。</p>
<ul>
<li>第一个问题是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。</li>
<li>第二个问题是 TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实 TCP 只要填满管道就可以了，不应<br>该接着填，直到连缓存也填满。</li>
</ul>
<p>为了优化这两个问题，后来有了 TCP BBR 拥塞算法。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓<br>存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。</p>
<h2 id="延迟确认"><a href="#延迟确认" class="headerlink" title="延迟确认"></a>延迟确认</h2><ul>
<li>不是每个数据包都对应一个 ACK 包，因为可以合并确认。</li>
<li>也不是接收端收到数据以后必须立刻马上回复确认包。</li>
</ul>
<p>如果收到一个数据包以后暂时没有数据要分给对端，它可以等一段时间（Linux 上是 40ms）再确认。如果这段时间刚好有数据要传给对端，ACK 就可<br>以随着数据一起发出去了。如果超过时间还没有数据要发送，也发送 ACK，以免对端以为丢包了。这种方式称为<strong>延迟确认</strong>。</p>
<p>可需要立即回复 ACK 的场景有：</p>
<ul>
<li>如果接收到了大于一个 frame 的报文，且需要调整窗口大小</li>
<li>处于 quickack 模式（tcp_in_quickack_mode）</li>
<li>收到乱序包（We have out of order data.）</li>
</ul>
<p>其它情况一律使用延迟确认的方式。</p>
<p>Linux 上并没有开关可以关闭延迟确认。</p>
<h2 id="定时器"><a href="#定时器" class="headerlink" title="定时器"></a>定时器</h2><p>TCP 为每条连接建立了 7 个定时器：</p>
<ul>
<li>连接建立定时器，当发送端发送 SYN 报文想建立一条新连接时，会开启连接建立定时器，如果没有收到对端的 ACK 包将进行重传。</li>
<li>重传定时器</li>
<li>延迟 ACK 定时器，在 TCP 收到数据包以后在没有数据包要回复时，不马上回复 ACK。这时开启一个定时器，等待一段时间看是否有数据需要回复。</li>
<li>PERSIST 定时器，为零窗口探测而准备的。当接收端 B 接收窗口为 0 时，发送端 A 此时不能再发送数据，发送端此时开启 Persist 定时器。</li>
<li>KEEPALIVE 定时器</li>
<li>FIN_WAIT_2 定时器，主动关闭的一方收到 ACK 以后从 FIN_WAIT_1 进入 FIN_WAIT_2 状态等待对端的 FIN 包的到来，FIN_WAIT_2 定时器<br>的作用是防止对方一直不发送 FIN 包，防止自己一直傻等。</li>
<li>TIME_WAIT 定时器，也称为 2MSL 定时器，主动关闭连接的一方在 TIME_WAIT 持续 2 个 MSL 的时间，超时后端口号可被安全的重用。</li>
</ul>

        <div id="react-support-footer-root"></div>
      </div>
    </div>
  </div>
</div>

    


    

    <!-- js vendors -->
    <script src="//code.jquery.com/jquery-3.2.1.min.js" crossorigin="anonymous"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/lunr.js/2.1.0/lunr.min.js"></script>

    <!-- js source  -->
    <script src="/network-protocol-learn/script/doc.js"></script>

    

  </body>
</html>
