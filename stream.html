<!DOCTYPE html>
<html lang="en">
  <head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    <title>Network protocol learning | 流媒体协议 </title>
    <meta name="description" content>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    

    <!-- fonts -->
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
    <link href="//fonts.googleapis.com/css?family=Ubuntu:300,400,500,600,700" rel="stylesheet">

    <!-- stylesheets -->
    <link rel="stylesheet" href="/network-protocol-learn/style/doc.css">

    <!-- favicon -->
    <link rel="icon" href="/network-protocol-learn/images/favicon.ico">

    

  </head>
  <body>

   <script>window.__INITIAL_STATE__ = {"page":{"title":"流媒体协议","path":"stream.html"},"data":{"navigation":{"logo":{"text":"Network Protocol Learn","type":"link","path":"index.html"},"main":[{"text":"IP","type":"link","path":"ip.html"},{"text":"物理层和链路层","type":"link","path":"physical_link.html"},{"text":"ICMP","type":"link","path":"icmp.html"},{"text":"网关","type":"link","path":"gateway.html"},{"text":"UDP","type":"link","path":"udp.html"},{"text":"TCP","type":"link","path":"tcp.html"},{"text":"HTTP","type":"link","path":"http.html"},{"text":"HTTPS","type":"link","path":"https.html"},{"text":"流媒体协议","type":"link","path":"stream.html"},{"text":"P2P 协议","type":"link","path":"p2p.html"},{"text":"DNS","type":"link","path":"dns.html"},{"text":"CDN","type":"link","path":"cdn.html"},{"text":"数据中心","type":"link","path":"data_center.html"},{"text":"VPN","type":"link","path":"vpn.html"},{"text":"移动网络","type":"link","path":"nemo.html"},{"text":"云中网络","type":"link","path":"cloud.html"},{"text":"容器网络","type":"link","path":"container.html"},{"text":"RPC","type":"link","path":"rpc.html"},{"text":"网络工具","type":"label"},{"text":"网络工具","type":"link","path":"net_tools.html"},{"text":"WireShark","type":"link","path":"wireshark.html"},{"text":"THEME","type":"label"},{"text":"使用文档主题","type":"link","path":"theme/theme-usage.html"},{"text":"SUPPORT AND FEEDBACK","type":"label"},{"text":"Raise an Issue on Github","type":"link","path":"https://github.com/shipengqi/network-protocol-learn/issues/new"}]}},"config":{"timezone":"UTC","root":"/network-protocol-learn/","time_format":"HH:mm:ss","theme":"../node_modules/hexo-theme-doc","theme_config":{"swagger_ui":{"version":2,"permalinks":true,"api_explorer":true,"download":"Download specification","show_extensions":false,"deep_linking":true,"display_operation_id":false,"doc_expansion":"none"},"search":{"skip":false,"background":false,"route":"/lunr.json"},"favicon":"images/favicon.ico"}}}</script>

    <div id="react-navigation-root"><div class="doc-navigation" data-reactroot><nav class="doc-navbar"><a href="/network-protocol-learn/index.html" class="doc-navbar__logo"><img src="/network-protocol-learn/images/logo.png" class="doc-navbar__logo__img"><span class="doc-navbar__logo__text">Network Protocol Learn</span></a><i class="dc-icon dc-icon--close dc-icon--interactive doc-sidebar-close doc-navbar__sidebar-close doc-navbar__sidebar-close--desktop"></i><i class="dc-icon dc-icon--menu dc-icon--interactive doc-sidebar-toggle doc-navbar__sidebar-toggle"></i></nav><nav class="doc-sidebar"><div class="doc-sidebar__vertical-menu"><i class="dc-icon dc-icon--menu dc-icon--interactive doc-sidebar-toggle doc-sidebar-toggle--primary doc-sidebar__vertical-menu__item"></i><i class="dc-icon dc-icon--search dc-icon--interactive doc-sidebar__vertical-menu__item doc-sidebar__vertical-menu__item--primary"></i></div><div class="doc-sidebar-content"><div class="doc-sidebar__search-form"></div><ul class="doc-sidebar-list"></ul></div></nav></div></div>
    <div class="doc-content">
  <div class="dc-page">
    <div class="dc-card">
      <div id="react-search-results-root"></div>
      <div id="page-content" class="doc-formatting">
        <h1 id="流媒体协议"><a href="#流媒体协议" class="headerlink" title="流媒体协议"></a>流媒体协议</h1><p>无论是直播还是点播，其实都是对于视频数据的传输。</p>
<p>视频是什么？其实就是快速播放一连串连续的图片。</p>
<p>每一张图片，我们称为一<strong>帧</strong>。只要每秒钟帧的数据足够多，也即播放得足够快。比如每秒 30 帧，以人的眼睛的敏感程度，是看不出这是一张张独<br>立的图片的，这就是我们常说的<strong>帧率（FPS）</strong>。</p>
<p>每一张图片，都是由<strong>像素</strong>组成的，假设为 <code>1024*768</code>。每个像素由 RGB 组成，每个 8 位，共 24 位。</p>
<p>那么每秒钟的视频有多大？</p>
<p><code>30 帧 × 1024 × 768 × 24 = 566,231,040Bits = 70,778,880Bytes</code></p>
<p>如果一分钟呢？ <code>4,246,732,800Bytes</code>，已经是 4 个 G 了。</p>
<p>这个数据量实在是太大，根本没办法存储和传输。如果这样存储，你的硬盘很快就满了；如果这样传输，那多少带宽也不够用啊！</p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>于是出现了<strong>编码</strong>，就是看如何用尽量少的 Bit 数保存视频，使播放的时候画面看起来仍然很精美。<strong>编码是一个压缩的过程</strong>。</p>
<p>之所以能够对视频流中的图片进行压缩，因为视频和图片有这样一些特点。</p>
<ul>
<li><strong>空间冗余</strong>：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，没必要每个像素都完整地保存，可以隔几<br>个保存一个，中间的用算法计算出来。</li>
<li><strong>时间冗余</strong>：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。</li>
<li><strong>视觉冗余</strong>：人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数据。</li>
<li><strong>编码冗余</strong>：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似霍夫曼编码（Huffman Coding）的思路。</li>
</ul>
<p>编码过程：</p>
<p><img src="images/stream/image-encode.jpg" alt></p>
<h3 id="视频编码的标准"><a href="#视频编码的标准" class="headerlink" title="视频编码的标准"></a>视频编码的标准</h3><p>ITU-T（国际电信联盟电信标准化部门，ITU Telecommunication Standardization Sector）与 MPEG 联合制定了 <strong>H.264/MPEG-4 AVC</strong>。</p>
<p>经过编码之后，一帧一帧的图像，就变成了二进制，这个二进制可以放在一个文件里面，按照一定的格式保存起来,例如 RMVB 和 MP4。</p>
<h2 id="如何在直播里看到帅哥美女？"><a href="#如何在直播里看到帅哥美女？" class="headerlink" title="如何在直播里看到帅哥美女？"></a>如何在直播里看到帅哥美女？</h2><p>这个二进制也可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。</p>
<p>网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络包，从而得到里面的视频流，这个过<br>程称为<strong>接流</strong>。</p>
<p>服务端接到视频流之后，可以对视频流进行一定的处理，例如<strong>转码</strong>，也即从一个编码格式，转成另一种格式。因为观众使用的客户端千差万别，要保<br>证他们都能看到直播。</p>
<p>流处理完毕之后，就可以等待观众的客户端来请求这些视频流。观众的客户端请求的过程称为<strong>拉流</strong>。</p>
<p>如果有非常多的观众，同时看一个视频直播，那都从一个服务器上拉流，压力太大了，因而需要一个视频的<strong>分发网络</strong>，将视频预先加载到就近的边缘<br>节点，这样大部分观众看的视频，是从边缘节点拉取的，就能降低服务器的压力。当观众的客户端将视频流拉下来之后，就需要进行<strong>解码</strong>，也即通过<br>上述过程的逆过程，将一串串看不懂的二进制，再转变成一帧帧生动的图片，在客户端播放出来，这样你就能看到美女帅哥啦。</p>
<p>直播过程:</p>
<p><img src="images/stream/livestreming.jpg" alt></p>
<h3 id="编码：如何将丰富多彩的图片变成二进制流？"><a href="#编码：如何将丰富多彩的图片变成二进制流？" class="headerlink" title="编码：如何将丰富多彩的图片变成二进制流？"></a>编码：如何将丰富多彩的图片变成二进制流？</h3><p>虽然我们说视频是一张张图片的序列，但是如果每张图片都完整，就太大了，因而会将视频序列分成三种帧:</p>
<ul>
<li><strong>I 帧</strong>，也称关键帧。里面是完整的图片，只需要本帧数据，就可以完成解码。</li>
<li><strong>P 帧</strong>，前向预测编码帧。P 帧表示的是这一帧跟之前的一个关键帧（或P 帧）的差别，解码时需要用之前缓存的画面，叠加上和本帧定义的差别，<br>生成最终画面。</li>
<li><strong>B 帧</strong>，双向预测内插编码帧。B 帧记录的是本帧与前后帧的差别。要解码 B 帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画<br>面的数据与本帧数据的叠加，取得最终的画面。</li>
</ul>
<p><strong>I 帧最完整，B 帧压缩率最高，而压缩后帧的序列，应该是在 IBBP 的间隔出现的。这就是通过时序进行编码。</strong></p>
<p><img src="images/stream/framing.jpg" alt></p>
<p>在一帧中，分成多个片，每个片中分成多个宏块，每个宏块分成多个子块，这样将一张大的图分解成一个个小块，可以方便进行<strong>空间上的编码</strong>。</p>
<p>尽管时空非常立体的组成了一个序列，但是总归还是要压缩成一个二进制流。这个流是有结构的，是一个个的<strong>网络提取层<br>单元（NALU，Network Abstraction Layer Unit）</strong>。变成这种格式就是为了传输，因为网络上的传输，默认的是一个个的包，因而这里也就分<br>成了一个个的单元。</p>
<p><img src="images/stream/nalu.jpg" alt></p>
<p><strong>一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，在每<br>一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列</strong>。</p>
<p>每一个 NALU 首先是一个起始标识符，用于标识 NALU 之间的间隔</p>
<p>NALU 头里面，主要的内容是类型 NAL Type:</p>
<ul>
<li>0x07 表示 SPS，是序列参数集，包括一个图像序列的所有信息，如图像尺寸、视频格式等。</li>
<li>0x08 表示 PPS，是图像参数集，包括一个图像的所有分片的所有相关信息，包括图像类型、序列号等。</li>
</ul>
<p>Payload 里面是 NALU 承载的数据。</p>
<h4 id="推流：如何把数据流打包传输到对端"><a href="#推流：如何把数据流打包传输到对端" class="headerlink" title="推流：如何把数据流打包传输到对端"></a>推流：如何把数据流打包传输到对端</h4><p>使用 <strong>RTMP 协议</strong>将这个二进制的流打包成网络包进行发送。这就进入了第二个过程，<strong>推流</strong>。</p>
<p><strong>RTMP 是基于 TCP 的，因而肯定需要双方建立一个 TCP 的连接。在有 TCP 的连接的基础上，还需要建立一个 RTMP 的连接</strong>。</p>
<p>RTMP 为什么需要建立一个单独的连接？</p>
<p>因为它们需要商量一些事情，保证以后的传输能正常进行。主要就是两个事情，一个是<strong>版本号</strong>，如果客户端、服务器的版本号不一致，则不能工作。<br>另一个就是<strong>时间戳</strong>，视频播放中，时间是很重要的，后面的数据流互通的时候，经常要带上时间戳的差值，因而一开始双方就要知道对方的时间戳。</p>
<p>握手之后，双方需要互相传递一些控制信息，例如 Chunk 块的大小、窗口大小等。</p>
<p>真正传输数据的时候，还是需要创建一个流 Stream，然后通过这个 Stream 来推流 publish。</p>
<p>推流的过程，就是将 NALU 放在 Message 里面发送，这个也称为 RTMP Packet 包。Message 的格式就像这样。</p>
<p>RTMP 在收发数据的时候并不是以 Message 为单位的，而是把 Message 拆分成 Chunk 发送，而且必须在一个 Chunk 发送完成之后，才能开始<br>发送下一个 Chunk。每个 Chunk 中都带有 Message ID，表示属于哪个 Message，接收端也会按照这个 ID 将 Chunk 组装成 Message。</p>
<p>数据推送到流媒体服务器过程：</p>
<p><img src="images/stream/pushstream.jpg" alt></p>
<p>然后直播的观众就可以通过 RTMP 协议从流媒体服务器上拉取，但是这么多的用户量，都去同一个地方拉取，服务器压力会很大，而且用户分布在全<br>国甚至全球，如果都去统一的一个地方下载，也会时延比较长，<br>需要有<strong>分发网络</strong>。</p>
<p><img src="images/stream/deliverynetwork.jpg" alt></p>
<h4 id="拉流：观众的客户端如何看到视频"><a href="#拉流：观众的客户端如何看到视频" class="headerlink" title="拉流：观众的客户端如何看到视频"></a>拉流：观众的客户端如何看到视频</h4><p><img src="images/stream/pullstream.jpg" alt></p>

        <div id="react-support-footer-root"></div>
      </div>
    </div>
  </div>
</div>

    


    

    <!-- js vendors -->
    <script src="//code.jquery.com/jquery-3.2.1.min.js" crossorigin="anonymous"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/lunr.js/2.1.0/lunr.min.js"></script>

    <!-- js source  -->
    <script src="/network-protocol-learn/script/doc.js"></script>

    

  </body>
</html>
